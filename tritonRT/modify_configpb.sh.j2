#!/bin/bash 

rm ./disk/model/{{ model }}/*.safetensors
rm ./disk/model/{{ model }}/*.bin

if [ '{{ model }}' == 'Llama-2-7b-hf' ]
then
    sed -i 's#${tokenizer_dir}#/{{ model }}/#' ./disk/inflight_batcher_llm/preprocessing/config.pbtxt
    sed -i 's#${tokenizer_type}#auto#' ./disk/inflight_batcher_llm/preprocessing/config.pbtxt
    sed -i 's#${tokenizer_dir}#/{{ model }}/#' ./disk/inflight_batcher_llm/postprocessing/config.pbtxt
    sed -i 's#${tokenizer_type}#auto#' ./disk/inflight_batcher_llm/postprocessing/config.pbtxt
    sed -i 's#${decoupled_mode}#false#' ./disk/inflight_batcher_llm/tensorrt_llm/config.pbtxt
    sed -i 's#${engine_dir}#/engines/1-gpu/#' ./disk/inflight_batcher_llm/tensorrt_llm/config.pbtxt
elif [ '{{ model }}' == 'gpt2-medium' ]
then
    sed -i 's#${tokenizer_dir}#/{{ model }}/#' ./disk/inflight_batcher_llm/preprocessing/config.pbtxt
    sed -i 's#${tokenizer_type}#auto#' ./disk/inflight_batcher_llm/preprocessing/config.pbtxt
    sed -i 's#${tokenizer_dir}#/{{ model }}/#' ./disk/inflight_batcher_llm/postprocessing/config.pbtxt
    sed -i 's#${tokenizer_type}#auto#' ./disk/inflight_batcher_llm/postprocessing/config.pbtxt
    sed -i 's#${decoupled_mode}#false#' ./disk/inflight_batcher_llm/tensorrt_llm/config.pbtxt
    sed -i 's#${engine_dir}#/engines/1-gpu/#' ./disk/inflight_batcher_llm/tensorrt_llm/config.pbtxt
    sed -i 's#${batch_scheduler_policy}#max_utilization#' ./disk/inflight_batcher_llm/tensorrt_llm/config.pbtxt
else
    echo "Unsupported model"
fi